{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomモジュールをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネイピア数\n",
    "$$e = (1+1/1000000000)^{1000000000}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def napiers_logarithm(x):\n",
    "    return (1 + 1 / x) ** x\n",
    "napier_number = napiers_logarithm(1000000000)  # e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シグモイド関数\n",
    "$$Sigmoid(x)=\\frac{1}{1+Napiers(1000000000)^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + napier_number ** -x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シグモイド関数の微分\n",
    "$$Sigmoid'(x)=Sigmoid(x)(1 - Sigmoid(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU関数\n",
    "$$ReLU(x) =\n",
    "        \\begin{cases}\n",
    "            x \\quad x \\geqq 0 \\\\\n",
    "            0 \\quad x < 0 \\\\\n",
    "        \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU関数の微分\n",
    "$$ReLU'(x) =\n",
    "        \\begin{cases}\n",
    "            1 \\quad x > 0 \\\\\n",
    "            0 \\quad x \\leqq 0 \\\\\n",
    "        \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    return 1 if x > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自然対数\n",
    "$$ln(x) = 2 \\sum_{n=1,3,5,\\dots}^{\\infty} \\frac{(z^n)}{n}, \\quad z = \\frac{x-1}{x+1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln(x, n_terms=100):\n",
    "    if x <= 0: raise ValueError(\"x must be positive\")\n",
    "    return (x - 1) / (x + 1) * sum([((x - 1) / (x + 1) ** n) / n for n in range(1, n_terms + 1, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスエントロピー損失\n",
    "$$L(y_{\\text{true}}, y_{\\text{pred}}) = - \\sum_{i=1}^{n} y_{\\text{true}_i} \\cdot \\ln(y_{\\text{pred}_i} + \\epsilon)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "    return -sum([t * ln(p + 1e-9) for t, p in zip(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークを初期化\n",
    "例:&emsp;入力層 -> 2,&emsp;隠れ層 -> [3, 3],&emsp;出力層 -> 1\n",
    "#### 重み\n",
    "$$n_{n}={2, 3, 3, 1}$$\n",
    "$$ random \\in [-1, 1] $$\n",
    "$$[[[random]*n_{1}]*n_{2}, [[random]*n_{2}]*n_{3}, [[random]*n_{3}]*n_{4}]$$\n",
    "#### バイアス\n",
    "$$n_{n}={3, 3, 1}$$\n",
    "$$ random \\in [-1, 1] $$\n",
    "$$[[random]*n_{1},[random]*n_{2},[random]*n_{3}]$$\n",
    "\n",
    "※ [n]*5 -> [n, n, n, n, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layer_sizes):  # initialize weights and biases\n",
    "    weights, biases = [], []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        weights.append([[random.uniform(-1, 1) for _ in range(layer_sizes[i])] for _ in range(layer_sizes[i+1])])  # [ {random_num *layer_sizes[i]} *layer_sizes[i+1] ]\n",
    "        biases.append([random.uniform(-1, 1) for _ in range(layer_sizes[i+1])])  # [ random_num *layer_sizes[i+1] ]\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 順伝播処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(inputs, weights, biases):  # forward propagation\n",
    "    activations = [inputs]\n",
    "    for W, b in zip(weights, biases):\n",
    "        activations.append([\n",
    "            relu(sum([activations[-1][i] * W[j][i] for i in range(len(activations[-1]))]) + b[j])\n",
    "            for j in range(len(b))\n",
    "        ])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逆伝播処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(activations, y_true, weights, biases, learning_rate):  # backward propagation\n",
    "    output_layer = activations[-1]\n",
    "    deltas = [[\n",
    "        (output_layer[i] - y_true[i]) * sigmoid_derivative(output_layer[i])\n",
    "        for i in range(len(y_true))\n",
    "    ]]\n",
    "    # Backpropagating the hidden layer error\n",
    "    for l in range(len(weights)-1, 0, -1):\n",
    "        deltas.insert(0, [\n",
    "            sum([deltas[0][k] * weights[l][k][j] for k in range(len(deltas[0]))]) * relu_derivative(activations[l][j])\n",
    "            for j in range(len(activations[l]))\n",
    "        ])\n",
    "    # Update the weights and biases\n",
    "    for l in range(len(weights)):\n",
    "        for i in range(len(weights[l])):\n",
    "            for j in range(len(weights[l][i])):\n",
    "                weights[l][i][j] -= learning_rate * deltas[l][i] * activations[l][j]\n",
    "            biases[l][i] -= learning_rate * deltas[l][i]\n",
    "\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, layer_sizes, epochs, learning_rate):\n",
    "    weights, biases = initialize_weights(layer_sizes)\n",
    "    weights_list = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(len(X)):\n",
    "            activations = forward_propagation(X[i], weights, biases)\n",
    "            total_loss += cross_entropy_loss(y[i], activations[-1])\n",
    "            weights, biases = backward_propagation(activations, y[i], weights, biases, learning_rate)\n",
    "            weights_list.append(weights)\n",
    "        \n",
    "        m = (epoch + (epochs // 20) - 1) // (epochs // 20)\n",
    "        print(f\"\\rEpoch {epoch+1}/{epochs}, Loss: {total_loss/len(X)}, [{'+'*m}{' '*(20-m)}]{' '*10}\",end=\"\")\n",
    "    print(\"\\nComplete\")\n",
    "    return weights, biases, weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメーターの設定および関数呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50000/50000, Loss: -1.373265586564151e-19, [++++++++++++++++++++]          \n",
      "Complete\n",
      "Inputs: [0, 0], Output: [0] Predict: [0], probability: 0\n",
      "Inputs: [0, 1], Output: [1] Predict: [1], probability: 1.0\n",
      "Inputs: [1, 0], Output: [1] Predict: [1], probability: 1.0\n",
      "Inputs: [1, 1], Output: [0] Predict: [0], probability: 0\n"
     ]
    }
   ],
   "source": [
    "# DataSet for XOR\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # Input\n",
    "y = [[0], [1], [1], [0]]  # Output\n",
    "\n",
    "epochs = 500  # Number of epochs\n",
    "learning_rate = 0.1  # Learning rate\n",
    "layer_sizes = [2, 8, 16, 8, 1]  # 2 input -> 8 hidden -> 16 hidden -> 8 hidden -> 1 output\n",
    "\n",
    "weights, biases, weights_list = train(X, y, layer_sizes, epochs, learning_rate)\n",
    "\n",
    "for i in range(len(X)):  # Prediction\n",
    "    activations = forward_propagation(X[i], weights, biases)\n",
    "    output = activations[-1]\n",
    "    binary_output = [1 if o >= 0.5 else 0 for o in output]\n",
    "    print(f\"Inputs: {X[i]}, Output: {y[i]} Predict: {binary_output}, probability: {round(output[0], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    \"\"\"weights を -1～1 から 0～255 に変換し、uint8形式で返す\"\"\"\n",
    "    weights = np.array(weights)  # リストをNumPy配列に変換\n",
    "    return ((weights + 1) * 128).astype(np.uint8)  # 0～255に正規化\n",
    "\n",
    "def create_frame_from_weights(current_weights, previous_weights, layer_sizes, frame_width, pixel_size=10):\n",
    "    \"\"\"各エポックごとに重みの変化を可視化したフレームを生成\"\"\"\n",
    "    max_neurons = max(layer_sizes)  # 縦のサイズ（最大ニューロン数）\n",
    "    frame = np.ones((max_neurons * pixel_size, frame_width * pixel_size, 3), dtype=np.uint8) * 255  # 白背景のフレームを作成\n",
    "\n",
    "    x_pos = 0\n",
    "    for layer_index, (current_layer_weights, previous_layer_weights) in enumerate(zip(current_weights, previous_weights)):\n",
    "        # 重みの変化を計算し、10000倍にスケーリング\n",
    "        weight_change = np.abs(np.array(current_layer_weights) - np.array(previous_layer_weights)) * 10000  # 重みの変化量\n",
    "        normalized_weights = normalize_weights(weight_change)  # 重みの変化量を正規化\n",
    "        \n",
    "        # 色を付けるためにカラーマップを使用\n",
    "        color_weights = cv2.applyColorMap(normalized_weights, cv2.COLORMAP_JET)  # カラーマップを適用\n",
    "        layer_height, layer_width, _ = color_weights.shape\n",
    "\n",
    "        # フレームにレイヤーの重みの変化をピクセルサイズで拡大表示\n",
    "        for i in range(layer_height):\n",
    "            for j in range(layer_width):\n",
    "                if x_pos + j < frame_width and i < max_neurons:\n",
    "                    # ピクセルサイズ分だけ重みを埋める（くっきり表示）\n",
    "                    frame[i * pixel_size:(i + 1) * pixel_size, \n",
    "                          (x_pos + j) * pixel_size:(x_pos + j + 1) * pixel_size] = color_weights[i, j]\n",
    "        x_pos += layer_width  # 次のレイヤーの配置位置を設定\n",
    "\n",
    "    return frame\n",
    "\n",
    "def weights_to_video(weights_list, layer_sizes, video_filename=\"weights_video.mp4\", pixel_size=10):\n",
    "    \"\"\"weights_list をエポックごとにフレームとして動画を作成\"\"\"\n",
    "    max_neurons = max(layer_sizes)  # 縦幅（最大ニューロン数）\n",
    "    frame_width = sum(layer_sizes[:-1])  # 横幅（全レイヤーの合計ニューロン数）\n",
    "\n",
    "    # 動画出力設定（フレームレート 10 FPS、各ピクセルがくっきり見えるように調整）\n",
    "    out = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 10,  # フレームレートを10に設定\n",
    "                          (frame_width * pixel_size, max_neurons * pixel_size), isColor=True)\n",
    "\n",
    "    previous_weights = weights_list[0]  # 最初のエポックの重みを設定\n",
    "\n",
    "    # 各エポックの重みをフレームに変換して書き込み\n",
    "    for epoch_index, current_weights in enumerate(weights_list):\n",
    "        if epoch_index > 0:\n",
    "            frame = create_frame_from_weights(current_weights, previous_weights, layer_sizes, frame_width, pixel_size=pixel_size)\n",
    "            out.write(frame)\n",
    "            print(f\"\\rProcessing epoch {epoch_index}/{len(weights_list) - 1}\", end=\"\")\n",
    "        previous_weights = current_weights  # 現在の重みを次のエポックの前の重みに設定\n",
    "\n",
    "    out.release()\n",
    "    print(\"\\n動画作成が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 31/199999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 199999/199999\n",
      "動画作成が完了しました。\n"
     ]
    }
   ],
   "source": [
    "# 使用例\n",
    "weights_to_video(weights_list, layer_sizes, video_filename=\"weights_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
