{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nn:\n",
    "    def __init__(self, hidden_func=\"relu\", output_func=\"sigmoid\", loss_func=\"cross_entropy_loss\", epochs=1000, learning_rate=0.01, random_state=None, layer_sizes=None):\n",
    "        activate_functions = {\"sigmoid\": self.sigmoid, \"relu\": self.relu, \"leaky_relu\": self.leaky_relu, \"identity\": self.identity}\n",
    "        loss_functions = {\"cross_entropy_loss\": self.cross_entropy_loss, \"mean_squared_error\": self.mean_squared_error, \"mean_absolute_error\": self.mean_absolute_error, \"binary_cross_entropy\": self.binary_cross_entropy_loss, \"categorical_cross_entropy\": self.categorical_cross_entropy_loss}\n",
    "        self.hidden_func = activate_functions[hidden_func]\n",
    "        self.output_func = activate_functions[output_func]\n",
    "        self.loss_func = loss_functions[loss_func]\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        if random_state is not None: random.seed(random_state)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.napier_number = self.napiers_logarithm(100000000)\n",
    "        self.tolerance = 1e-10  # sqrt許容誤差\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.activations = []\n",
    "    \n",
    "    def napiers_logarithm(self, x):\n",
    "        \"\"\"\n",
    "        ネイピア数を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return (1 + 1 / x) ** x\n",
    "    \n",
    "    def ln(self, x, max_iter=20, tol=1e-12):\n",
    "        \"\"\"\n",
    "        自然対数を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            max_iter (int): 最大反復回数\n",
    "            tol (float): 許容誤差\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: x が正でない場合\n",
    "        \"\"\"\n",
    "        if x <= 0: raise ValueError(\"x must be positive\")\n",
    "        k = 0\n",
    "        while x > 2:\n",
    "            x /= 2\n",
    "            k += 1\n",
    "        while x < 0.5:\n",
    "            x *= 2\n",
    "            k -= 1\n",
    "        y = x - 1  # ln(1) = 0 付近の値から開始\n",
    "        for _ in range(max_iter):\n",
    "            prev_y = y\n",
    "            y -= (2.718281828459045**y - x) / (2.718281828459045**y)  # f(y) / f'(y)\n",
    "            if abs(y - prev_y) < tol:\n",
    "                break\n",
    "        return y + k * 0.6931471805599453  # ln(2) ≈ 0.693147\n",
    "    \n",
    "    def sqrt(self, x):\n",
    "        \"\"\"\n",
    "        平方根を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        estimate = x / 2.0  # 初期推定値\n",
    "        while True:\n",
    "            new_estimate = (estimate + x / estimate) / 2  # ニュートン法による更新\n",
    "            if abs(new_estimate - estimate) < self.tolerance:  # 収束したら終了\n",
    "                return new_estimate\n",
    "            estimate = new_estimate  # 推定値を更新\n",
    "\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        Sigmoid 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.sigmoid_derivative(x)\n",
    "        return 1 / (1 + self.napier_number ** -x)\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "\n",
    "    def relu(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        ReLU 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.relu_derivative(x)\n",
    "        return max(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"\n",
    "        ReLU 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "\n",
    "    def leaky_relu(self, x, alpha=0.01, derivative=False):\n",
    "        \"\"\"\n",
    "        Leaky ReLU 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            alpha (float): ハイパーパラメータ\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.leaky_relu_derivative(x, alpha)\n",
    "        return x if x > 0 else alpha * x\n",
    "\n",
    "    def leaky_relu_derivative(self, x, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Leaky ReLU 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            alpha (float): ハイパーパラメータ\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return 1 if x > 0 else alpha\n",
    "    \n",
    "\n",
    "    def identity(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        恒等関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.identity_derivative(x)\n",
    "        return x\n",
    "\n",
    "    def identity_derivative(self, x):\n",
    "        \"\"\"\n",
    "        恒等関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力(未使用)\n",
    "        \n",
    "        Returns:\n",
    "            int: 出力\n",
    "        \"\"\"\n",
    "        return 1\n",
    "    \n",
    "\n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return -sum([t * self.ln(p + 1e-9) for t, p in zip(y_true, y_pred)])\n",
    "    \n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        平均二乗誤差を求める関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return sum([(t - p) ** 2 for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def mean_absolute_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        平均絶対誤差を求める関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return sum([abs(t - p) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def binary_cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        バイナリ交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        epsilon = 1e-9  # 0で割るのを防ぐための小さな値\n",
    "        return -sum([t * self.ln(p + epsilon) + (1 - t) * self.ln(1 - p + epsilon) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def categorical_cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        カテゴリカル交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        epsilon = 1e-9  # 0で割るのを防ぐための小さな値\n",
    "        return -sum([t * self.ln(p + epsilon) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def initialize_weights(self):  # 重みとバイアスの初期化\n",
    "        \"\"\"\n",
    "        重みとバイアスを初期化する関数\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layer_sizes) - 1):\n",
    "            limit = self.sqrt(6 / (self.layer_sizes[i] + self.layer_sizes[i+1]))  # 重みの初期化に使う乱数の範囲\n",
    "            self.weights.append([[random.uniform(-limit, limit) for _ in range(self.layer_sizes[i])] for _ in range(self.layer_sizes[i+1])])  # 重みは -limit から limit の間の乱数で初期化\n",
    "            self.biases.append([0 for _ in range(self.layer_sizes[i+1])])  # バイアスは0で初期化\n",
    "    \n",
    "    def forward_propagation(self, inputs):  # 順伝播処理\n",
    "        \"\"\"\n",
    "        順伝播処理を行う関数\n",
    "\n",
    "        Args:\n",
    "            inputs (list): 入力\n",
    "        \"\"\"\n",
    "        self.activations = [inputs]\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = [\n",
    "                sum([self.activations[-1][i] * W[j][i] for i in range(len(self.activations[-1]))]) + b[j]\n",
    "                for j in range(len(b))\n",
    "            ]\n",
    "            if W != self.weights[-1]:\n",
    "                self.activations.append([self.hidden_func(z_i, derivative=False) for z_i in z])\n",
    "            else:\n",
    "                self.activations.append([self.output_func(z_i, derivative=False) for z_i in z])\n",
    "\n",
    "    def backward_propagation(self, y_true):  # 逆伝播処理\n",
    "        \"\"\"\n",
    "        逆伝播処理を行う関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "        \"\"\"\n",
    "        output_layer = self.activations[-1]\n",
    "        errors = [\n",
    "            (output_layer[i] - y_true[i]) * self.output_func(output_layer[i], derivative=True)\n",
    "            for i in range(len(y_true))\n",
    "        ]\n",
    "        deltas = [errors]\n",
    "        # 隠れ層の誤差を計算\n",
    "        for l in range(len(self.weights)-1, 0, -1):\n",
    "            hidden_errors = [\n",
    "                sum([deltas[0][k] * self.weights[l][k][j] for k in range(len(deltas[0]))]) * self.hidden_func(self.activations[l][j], derivative=True)\n",
    "                for j in range(len(self.activations[l]))\n",
    "            ]\n",
    "            deltas.insert(0, hidden_errors)\n",
    "        # 重みとバイアスを更新\n",
    "        for l in range(len(self.weights)):\n",
    "            for i in range(len(self.weights[l])):\n",
    "                for j in range(len(self.weights[l][i])):\n",
    "                    self.weights[l][i][j] -= self.learning_rate * deltas[l][i] * self.activations[l][j]\n",
    "                self.biases[l][i] -= self.learning_rate * deltas[l][i]\n",
    "    \n",
    "    def fit(self, X, y):  # 学習\n",
    "        \"\"\"\n",
    "        ニューラルネットワークを学習する関数\n",
    "\n",
    "        Args:\n",
    "            X (list): 入力\n",
    "            y (list): 正解ラベル\n",
    "            layer_sizes (list): 各層のユニット数\n",
    "            epochs (int): エポック数\n",
    "            learning_rate (float): 学習率\n",
    "        \n",
    "        Returns:\n",
    "            tuple: 重みとバイアス\n",
    "        \"\"\"\n",
    "        self.initialize_weights()\n",
    "        start = time.time()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                self.forward_propagation(X[i])\n",
    "                total_loss += self.loss_func(y[i], self.activations[-1])\n",
    "                self.backward_propagation(y[i])\n",
    "            m = epoch // (self.epochs // 20) + 1\n",
    "            print(f\"\\rEpoch {epoch+1}/{self.epochs}, Loss: {total_loss/len(X):.10f}, {'█'*m}{'-'*(20-m)} {int((epoch + 1) / self.epochs * 100)}%,{' '*5}\",end=\"\")\n",
    "        print(f\"Training time: {time.time()-start:.2f} seconds\")\n",
    "        \n",
    "    def predict(self, X):  # 予測\n",
    "        \"\"\"\n",
    "        予測を行う関数\n",
    "\n",
    "        Args:\n",
    "            X (list): 入力\n",
    "        \n",
    "        Returns:\n",
    "            list: 出力\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for i in range(len(X)):  # Prediction\n",
    "            self.forward_propagation(X[i])\n",
    "            outputs.append(self.activations[-1])\n",
    "        return outputs\n",
    "    \n",
    "    def accuracy(self, X, y, predict):  # 予測精度の計算\n",
    "        \"\"\"\n",
    "        予測精度を計算する関数\n",
    "\n",
    "        Args:\n",
    "            X (list): 入力\n",
    "            y (list): 正解ラベル\n",
    "            predict (list): 予測値\n",
    "        \n",
    "        Returns:\n",
    "            float: 予測精度\n",
    "        \"\"\"\n",
    "        total_loss = 0\n",
    "        for i in range(len(predict)):  # Prediction\n",
    "            print(f\"入力: {X[i]}, 正解: {y[i]}, 予測値: {predict[i]}\")\n",
    "            total_loss += self.loss_func(y[i], predict[i])\n",
    "        print(f\"Loss: {total_loss / len(predict):.10f}\")\n",
    "        return total_loss / len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, denomalize=False, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    データを正規化する関数\n",
    "\n",
    "    Args:\n",
    "        data (list): 入力データ\n",
    "        denomalize (bool): 逆正規化を行うかどうか\n",
    "        min_val (float): 最小値\n",
    "        max_val (float): 最大値\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 正規化されたデータ、最小値、最大値もしくは逆正規化されたデータ\n",
    "    \"\"\"\n",
    "    if denomalize:\n",
    "        return [[x * (max_val - min_val) + min_val for x in sublist] for sublist in data]\n",
    "    min_val = min(min(sublist) for sublist in data)\n",
    "    max_val = max(max(sublist) for sublist in data)\n",
    "    nomalized_data = [[(x - min_val) / (max_val - min_val) for x in sublist] for sublist in data]\n",
    "    return nomalized_data, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data, unstandardize=False, mean=None, std_dev=None):\n",
    "    \"\"\"\n",
    "    データを標準化する関数\n",
    "\n",
    "    Args:\n",
    "        data (list): 入力データ\n",
    "        unstandardize (bool): 逆標準化を行うかどうか\n",
    "        mean (float): 平均\n",
    "        std_dev (float): 標準偏差\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 標準化されたデータ、平均、標準偏差もしくは逆標準化されたデータ\n",
    "    \"\"\"\n",
    "    if unstandardize:\n",
    "        return [[x * std_dev + mean for x in sublist] for sublist in data]\n",
    "    mean = sum(sum(sublist) for sublist in data) / (len(data) * len(data[0]))\n",
    "    std_dev = (sum((x - mean) ** 2 for sublist in data for x in sublist) / (len(data) * len(data[0]))) ** 0.5\n",
    "    standardized_data = [[(x - mean) / std_dev for x in sublist] for sublist in data]\n",
    "    return standardized_data, mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(labels, decoding=False, label_to_index=None):\n",
    "    \"\"\"\n",
    "    ラベルエンコーディングを行う関数\n",
    "\n",
    "    Args:\n",
    "        labels (list): カテゴリカルデータのリスト(デコードを行う際はエンコードした元文字列(現数値)のみを指定可能)\n",
    "        decoding (bool): デコードを行うかどうか(デコードを行う際は label_to_index を指定)\n",
    "        label_to_index (dict): ラベルとインデックスのマッピング\n",
    "    \n",
    "    Returns:\n",
    "        tuple: エンコードされたラベル、ラベルとインデックスのマッピング\n",
    "    \"\"\"\n",
    "    if decoding:\n",
    "        return [[list(label_to_index.keys())[list(label_to_index.values()).index(label)] for label in sublist] for sublist in labels]\n",
    "    str_labels = [label for label in sum(labels, []) if type(label) == str]\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(set(str_labels)))}\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] in label_to_index and type(labels[i][j]) == str:\n",
    "                labels[i][j] = label_to_index[labels[i][j]]\n",
    "    return labels, label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels, decoding=False, label_to_index=None):\n",
    "    \"\"\"\n",
    "    ワンホットエンコーディングを行う関数\n",
    "    \n",
    "    Args:\n",
    "        labels (list): カテゴリカルデータのリスト(デコードを行う際はエンコードした元文字列(現数値)のみを指定可能)\n",
    "        decoding (bool): デコードを行うかどうか(デコードを行う際は label_to_index を指定)\n",
    "        label_to_index (dict): ラベルとインデックスのマッピング\n",
    "    \n",
    "    Returns:\n",
    "        tuple: エンコードされたラベル、ラベルとインデックスのマッピング\n",
    "    \"\"\"\n",
    "    if decoding:\n",
    "        return[[k] for sublist in labels for i, x in enumerate(sublist) for k in label_to_index if x == 1 and i == label_to_index[k]]\n",
    "    str_labels = [label for label in sum(labels, []) if type(label) == str]\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(set(str_labels)))}\n",
    "    zeros = [0] * len(label_to_index)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] in label_to_index and type(labels[i][j]) == str:\n",
    "                labels[i][j] = zeros[:label_to_index[labels[i][j]]] + [1] + zeros[label_to_index[labels[i][j]]+1:]\n",
    "    return [[x for y in sublist for x in (y if isinstance(y, list) else [y])] for sublist in labels], label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, train_size=0.8, random_state=None):  # データセットを学習用とテスト用に分割\n",
    "    \"\"\"\n",
    "    データセットを学習用とテスト用に分割する関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        y (list): 正解ラベル\n",
    "        train_size (float): 学習データの割合\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 学習用データとテスト用データ\n",
    "    \"\"\"\n",
    "    if random_state is not None: random.seed(random_state)\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    X_train, y_train = [X[i] for i in indices[:int(n*train_size)]], [y[i] for i in indices[:int(n*train_size)]]\n",
    "    X_test, y_test = [X[i] for i in indices[int(n*train_size):]], [y[i] for i in indices[int(n*train_size):]]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000, Loss: 0.0000962872, ████████████████████ 100%,     Training time: 4.08 seconds\n",
      "入力: [0.9811496871982601, 0.5362157324787219], 正解: [1.517365419676982], 予測値: [1.5157466746376507]\n",
      "入力: [0.20425919942353643, 0.7161918007894148], 正解: [0.9204510002129512], 予測値: [0.9221888284971251]\n",
      "入力: [0.33808556214745533, 0.5883087184572333], 正解: [0.9263942806046886], 予測値: [0.9393823858043686]\n",
      "入力: [0.9984544408544423, 0.9960964478550944], 正解: [1.994550888709537], 予測値: [1.9754320390084175]\n",
      "入力: [0.4026212821022688, 0.33930260539496315], 正解: [0.7419238874972319], 予測値: [0.7620758557951799]\n",
      "入力: [0.15743272793948326, 0.9607789032744504], 正解: [1.1182116312139336], 予測値: [1.1072286363856934]\n",
      "入力: [0.6539763177107326, 0.007823107152157949], 正解: [0.6617994248628906], 予測値: [0.6216969808592374]\n",
      "入力: [0.42357577256372636, 0.27668022397225167], 正解: [0.700255996535978], 予測値: [0.7143000589034718]\n",
      "入力: [0.5503253124498481, 0.05058832952488124], 正解: [0.6009136419747293], 予測値: [0.5779290277325593]\n",
      "入力: [0.10703597770941764, 0.5532236408848159], 正解: [0.6602596185942335], 予測値: [0.6563161961341795]\n",
      "入力: [0.9689962572847513, 0.9263669830081276], 正解: [1.8953632402928788], 予測値: [1.882594689753497]\n",
      "入力: [0.22894178381115438, 0.905420013006128], 正解: [1.1343617968172823], 予測値: [1.1276375951826716]\n",
      "入力: [0.8596354002537465, 0.07085734988865344], 正解: [0.9304927501424], 予測値: [0.9006014081187622]\n",
      "入力: [0.8461037132948555, 0.09229846771273342], 正解: [0.9384021810075889], 予測値: [0.9129230360361082]\n",
      "入力: [0.4063773898321168, 0.6206615101507128], 正解: [1.0270388999828297], 予測値: [1.0429958081866282]\n",
      "入力: [0.4218816398344042, 0.27854514466694047], 正解: [0.7004267845013447], 予測値: [0.7147952309802781]\n",
      "入力: [0.8989246365264746, 0.21007653833975404], 正解: [1.1090011748662287], 予測値: [1.0966296951374277]\n",
      "入力: [0.5945191535334412, 0.6193815103321031], 正解: [1.2139006638655443], 予測値: [1.2291974781702089]\n",
      "入力: [0.7873745091354711, 0.10809562640295711], 正解: [0.8954701355384282], 予測値: [0.8740354650280643]\n",
      "入力: [0.2498064478821005, 0.9232655992760128], 正解: [1.1730720471581133], 予測値: [1.1647963379568655]\n",
      "入力: [0.43810008391450406, 0.5175758410355906], 正解: [0.9556759249500947], 予測値: [0.9768712706883337]\n",
      "入力: [0.02366443470145152, 0.19312978832770866], 正解: [0.21679422302916018], 予測値: [0.2429654385983559]\n",
      "入力: [0.6116777657259501, 0.9872330636315043], 正解: [1.5989108293574543], 予測値: [1.5839060022560902]\n",
      "入力: [0.4603032346789421, 0.30519086733860057], 正解: [0.7654941020175426], 予測値: [0.782667378211085]\n",
      "入力: [0.26520041475040135, 0.9332593779937091], 正解: [1.1984597927441105], 予測値: [1.1893001288253577]\n",
      "入力: [0.810749316574389, 0.26680570959447203], 正解: [1.0775550261688611], 予測値: [1.0769763908855072]\n",
      "入力: [0.8486957344143055, 0.16631111060391401], 正解: [1.0150068450182195], 予測値: [1.0003611615206442]\n",
      "入力: [0.7412309083479308, 0.5516804211263913], 正解: [1.2929113294743222], 予測値: [1.3131753829248143]\n",
      "入力: [0.864605696219964, 0.9762060329309629], 正解: [1.8408117291509267], 予測値: [1.824683531599645]\n",
      "入力: [0.3082583499301337, 0.89898148874259], 正解: [1.2072398386727237], 予測値: [1.2007221563440273]\n",
      "入力: [0.7176121871387979, 0.20359731232745293], 正解: [0.9212094994662509], 予測値: [0.9158898461235976]\n",
      "入力: [0.26520305817215195, 0.7840706019485694], 正解: [1.0492736601207213], 予測値: [1.052375051486862]\n",
      "入力: [0.4010402925494526, 0.058635399972178925], 正解: [0.45967569252163154], 予測値: [0.4422392005260227]\n",
      "入力: [0.8022351389371389, 0.8640640283752794], 正解: [1.6662991673124183], 予測値: [1.6605247543430508]\n",
      "入力: [0.9668891040483611, 0.2791249927218714], 正解: [1.2460140967702324], 予測値: [1.2312572690408965]\n",
      "入力: [0.07099308600903254, 0.6311029572700989], 正解: [0.7020960432791314], 予測値: [0.6946993081084446]\n",
      "入力: [0.8808641736864395, 0.8792702424845428], 正解: [1.7601344161709824], 予測値: [1.7522964205782836]\n",
      "入力: [0.8345950198860167, 0.582509566489794], 正解: [1.4171045863758107], 予測値: [1.4320560085808944]\n",
      "入力: [0.8074969977666434, 0.1904099143618777], 正解: [0.9979069121285211], 予測値: [0.9880171068081226]\n",
      "入力: [0.0035456890877823, 0.7711192230196271], 正解: [0.7746649121074094], 予測値: [0.7623143142980887]\n",
      "入力: [0.024786361898188725, 0.7365644717550821], 正解: [0.7613508336532708], 予測値: [0.7494710682227866]\n",
      "入力: [0.4235786230199208, 0.467024668036675], 正解: [0.8906032910565957], 予測値: [0.9110981779936184]\n",
      "入力: [0.8616725363527911, 0.24865633392028563], 正解: [1.1103288702730767], 予測値: [1.1038762489709164]\n",
      "入力: [0.3789731189769161, 0.9853088437797259], 正解: [1.364281962756642], 予測値: [1.3503818332558133]\n",
      "入力: [0.9573176408596732, 0.9954226894927138], 正解: [1.9527403303523871], 予測値: [1.9340668607251223]\n",
      "入力: [0.5421952013742742, 0.7479755603790641], 正解: [1.2901707617533384], 予測値: [1.295111920044738]\n",
      "入力: [0.7953454991528618, 0.22759548740777036], 正解: [1.022940986560632], 予測値: [1.01888726064432]\n",
      "入力: [0.230114732596577, 0.22021738445155947], 正解: [0.45033211704813647], 予測値: [0.45884809591753906]\n",
      "入力: [0.7290758494598506, 0.6733645472933015], 正解: [1.402440396753152], 予測値: [1.4127532935725915]\n",
      "入力: [0.7801162418714427, 0.8841347014510089], 正解: [1.6642509433224517], 予測値: [1.6569363127292336]\n",
      "Loss: 0.0002362020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00023620200663359352"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # 入力\n",
    "# y = [[1], [0], [0], [1]]  # 出力\n",
    "\n",
    "X = [[random.random(), random.random()] for _ in range(100)]\n",
    "y = [[x[0] + x[1]] for x in X]\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(X, y, train_size=0.5, random_state=42)  # データセットを学習用とテスト用に分割\n",
    "\n",
    "epochs = 1000  # エポック数\n",
    "learning_rate = 0.01  # 学習率\n",
    "layer_sizes = [len(X[0]), 8, 8, 8, len(y[0])]  # 各層のユニット数\n",
    "\n",
    "hidden_activation = \"relu\"\n",
    "output_activation = \"identity\"\n",
    "loss = \"mean_squared_error\"\n",
    "\n",
    "random_state = 42  # 乱数シード\n",
    "\n",
    "nn = Nn(hidden_activation, output_activation, loss, epochs, learning_rate, random_state, layer_sizes)\n",
    "nn.fit(X_train, y_train)\n",
    "predictions = nn.predict(X_test)\n",
    "nn.accuracy(X_test, y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
