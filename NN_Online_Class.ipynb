{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nn:\n",
    "    def __init__(self, hidden_func=\"relu\", output_func=\"sigmoid\", loss_func=\"cross_entropy_loss\", epochs=1000, learning_rate=0.01, random_state=None, layer_sizes=None):\n",
    "        activate_functions = {\"sigmoid\": self.sigmoid, \"relu\": self.relu, \"leaky_relu\": self.leaky_relu, \"identity\": self.identity}\n",
    "        loss_functions = {\"cross_entropy_loss\": self.cross_entropy_loss, \"mean_squared_error\": self.mean_squared_error, \"mean_absolute_error\": self.mean_absolute_error, \"binary_cross_entropy\": self.binary_cross_entropy_loss, \"categorical_cross_entropy\": self.categorical_cross_entropy_loss}\n",
    "        self.hidden_func = activate_functions[hidden_func]\n",
    "        self.output_func = activate_functions[output_func]\n",
    "        self.loss_func = loss_functions[loss_func]\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        if random_state is not None: random.seed(random_state)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.napier_number = self.napiers_logarithm(100000000)\n",
    "        self.tolerance = 1e-10  # sqrt許容誤差\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.activations = []\n",
    "    \n",
    "    def napiers_logarithm(self, x):\n",
    "        \"\"\"\n",
    "        ネイピア数を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return (1 + 1 / x) ** x\n",
    "    \n",
    "    def ln(self, x, max_iter=20, tol=1e-12):\n",
    "        \"\"\"\n",
    "        自然対数を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            max_iter (int): 最大反復回数\n",
    "            tol (float): 許容誤差\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: x が正でない場合\n",
    "        \"\"\"\n",
    "        if x <= 0: raise ValueError(\"x must be positive\")\n",
    "        k = 0\n",
    "        while x > 2:\n",
    "            x /= 2\n",
    "            k += 1\n",
    "        while x < 0.5:\n",
    "            x *= 2\n",
    "            k -= 1\n",
    "        y = x - 1  # ln(1) = 0 付近の値から開始\n",
    "        for _ in range(max_iter):\n",
    "            prev_y = y\n",
    "            y -= (2.718281828459045**y - x) / (2.718281828459045**y)  # f(y) / f'(y)\n",
    "            if abs(y - prev_y) < tol:\n",
    "                break\n",
    "        return y + k * 0.6931471805599453  # ln(2) ≈ 0.693147\n",
    "    \n",
    "    def sqrt(self, x):\n",
    "        \"\"\"\n",
    "        平方根を求める関数\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        estimate = x / 2.0  # 初期推定値\n",
    "        while True:\n",
    "            new_estimate = (estimate + x / estimate) / 2  # ニュートン法による更新\n",
    "            if abs(new_estimate - estimate) < self.tolerance:  # 収束したら終了\n",
    "                return new_estimate\n",
    "            estimate = new_estimate  # 推定値を更新\n",
    "\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        Sigmoid 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.sigmoid_derivative(x)\n",
    "        return 1 / (1 + self.napier_number ** -x)\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "\n",
    "    def relu(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        ReLU 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.relu_derivative(x)\n",
    "        return max(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"\n",
    "        ReLU 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "\n",
    "    def leaky_relu(self, x, alpha=0.01, derivative=False):\n",
    "        \"\"\"\n",
    "        Leaky ReLU 関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            alpha (float): ハイパーパラメータ\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.leaky_relu_derivative(x, alpha)\n",
    "        return x if x > 0 else alpha * x\n",
    "\n",
    "    def leaky_relu_derivative(self, x, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Leaky ReLU 関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            alpha (float): ハイパーパラメータ\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        return 1 if x > 0 else alpha\n",
    "    \n",
    "\n",
    "    def identity(self, x, derivative=False):\n",
    "        \"\"\"\n",
    "        恒等関数およびその微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力\n",
    "            derivative (bool): 微分を計算するかどうか\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \"\"\"\n",
    "        if derivative:\n",
    "            return self.identity_derivative(x)\n",
    "        return x\n",
    "\n",
    "    def identity_derivative(self, x):\n",
    "        \"\"\"\n",
    "        恒等関数の微分\n",
    "\n",
    "        Args:\n",
    "            x (float): 入力(未使用)\n",
    "        \n",
    "        Returns:\n",
    "            int: 出力\n",
    "        \"\"\"\n",
    "        return 1\n",
    "    \n",
    "\n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return -sum([t * self.ln(p + 1e-9) for t, p in zip(y_true, y_pred)])\n",
    "    \n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        平均二乗誤差を求める関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return sum([(t - p) ** 2 for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def mean_absolute_error(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        平均絶対誤差を求める関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        return sum([abs(t - p) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def binary_cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        バイナリ交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        epsilon = 1e-9  # 0で割るのを防ぐための小さな値\n",
    "        return -sum([t * self.ln(p + epsilon) + (1 - t) * self.ln(1 - p + epsilon) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def categorical_cross_entropy_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        カテゴリカル交差エントロピー損失関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "            y_pred (list): 予測ラベル\n",
    "        \n",
    "        Returns:\n",
    "            float: 出力\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: 入力リストの長さが異なる場合\n",
    "        \"\"\"\n",
    "        if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "        epsilon = 1e-9  # 0で割るのを防ぐための小さな値\n",
    "        return -sum([t * self.ln(p + epsilon) for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    \n",
    "    def initialize_weights(self):  # 重みとバイアスの初期化\n",
    "        \"\"\"\n",
    "        重みとバイアスを初期化する関数\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layer_sizes) - 1):\n",
    "            limit = self.sqrt(6 / (self.layer_sizes[i] + self.layer_sizes[i+1]))  # 重みの初期化に使う乱数の範囲\n",
    "            self.weights.append([[random.uniform(-limit, limit) for _ in range(self.layer_sizes[i])] for _ in range(self.layer_sizes[i+1])])  # 重みは -limit から limit の間の乱数で初期化\n",
    "            self.biases.append([0 for _ in range(self.layer_sizes[i+1])])  # バイアスは0で初期化\n",
    "    \n",
    "    def forward_propagation(self, inputs):  # 順伝播処理\n",
    "        \"\"\"\n",
    "        順伝播処理を行う関数\n",
    "\n",
    "        Args:\n",
    "            inputs (list): 入力\n",
    "        \"\"\"\n",
    "        self.activations = [inputs]\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = [\n",
    "                sum([self.activations[-1][i] * W[j][i] for i in range(len(self.activations[-1]))]) + b[j]\n",
    "                for j in range(len(b))\n",
    "            ]\n",
    "            if W != self.weights[-1]:\n",
    "                self.activations.append([self.hidden_func(z_i, derivative=False) for z_i in z])\n",
    "            else:\n",
    "                self.activations.append([self.output_func(z_i, derivative=False) for z_i in z])\n",
    "\n",
    "    def backward_propagation(self, y_true):  # 逆伝播処理\n",
    "        \"\"\"\n",
    "        逆伝播処理を行う関数\n",
    "\n",
    "        Args:\n",
    "            y_true (list): 正解ラベル\n",
    "        \"\"\"\n",
    "        output_layer = self.activations[-1]\n",
    "        errors = [\n",
    "            (output_layer[i] - y_true[i]) * self.output_func(output_layer[i], derivative=True)\n",
    "            for i in range(len(y_true))\n",
    "        ]\n",
    "        deltas = [errors]\n",
    "        # 隠れ層の誤差を計算\n",
    "        for l in range(len(self.weights)-1, 0, -1):\n",
    "            hidden_errors = [\n",
    "                sum([deltas[0][k] * self.weights[l][k][j] for k in range(len(deltas[0]))]) * self.hidden_func(self.activations[l][j], derivative=True)\n",
    "                for j in range(len(self.activations[l]))\n",
    "            ]\n",
    "            deltas.insert(0, hidden_errors)\n",
    "        # 重みとバイアスを更新\n",
    "        for l in range(len(self.weights)):\n",
    "            for i in range(len(self.weights[l])):\n",
    "                for j in range(len(self.weights[l][i])):\n",
    "                    self.weights[l][i][j] -= self.learning_rate * deltas[l][i] * self.activations[l][j]\n",
    "                self.biases[l][i] -= self.learning_rate * deltas[l][i]\n",
    "    \n",
    "    def fit(self, X, y):  # 学習\n",
    "        \"\"\"\n",
    "        ニューラルネットワークを学習する関数\n",
    "\n",
    "        Args:\n",
    "            X (list): 入力\n",
    "            y (list): 正解ラベル\n",
    "            layer_sizes (list): 各層のユニット数\n",
    "            epochs (int): エポック数\n",
    "            learning_rate (float): 学習率\n",
    "        \n",
    "        Returns:\n",
    "            tuple: 重みとバイアス\n",
    "        \"\"\"\n",
    "        self.initialize_weights()\n",
    "        start = time.time()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                self.forward_propagation(X[i])\n",
    "                total_loss += self.loss_func(y[i], self.activations[-1])\n",
    "                self.backward_propagation(y[i])\n",
    "            m = epoch // (self.epochs // 20) + 1\n",
    "            print(f\"\\rEpoch {epoch+1}/{self.epochs}, Loss: {total_loss/len(X):.10f}, {'█'*m}{'-'*(20-m)} {int((epoch + 1) / self.epochs * 100)}%,{' '*5}\",end=\"\")\n",
    "        print(f\"Training time: {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, denomalize=False, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    データを正規化する関数\n",
    "\n",
    "    Args:\n",
    "        data (list): 入力データ\n",
    "        denomalize (bool): 逆正規化を行うかどうか\n",
    "        min_val (float): 最小値\n",
    "        max_val (float): 最大値\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 正規化されたデータ、最小値、最大値もしくは逆正規化されたデータ\n",
    "    \"\"\"\n",
    "    if denomalize:\n",
    "        return [[x * (max_val - min_val) + min_val for x in sublist] for sublist in data]\n",
    "    min_val = min(min(sublist) for sublist in data)\n",
    "    max_val = max(max(sublist) for sublist in data)\n",
    "    nomalized_data = [[(x - min_val) / (max_val - min_val) for x in sublist] for sublist in data]\n",
    "    return nomalized_data, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data, unstandardize=False, mean=None, std_dev=None):\n",
    "    \"\"\"\n",
    "    データを標準化する関数\n",
    "\n",
    "    Args:\n",
    "        data (list): 入力データ\n",
    "        unstandardize (bool): 逆標準化を行うかどうか\n",
    "        mean (float): 平均\n",
    "        std_dev (float): 標準偏差\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 標準化されたデータ、平均、標準偏差もしくは逆標準化されたデータ\n",
    "    \"\"\"\n",
    "    if unstandardize:\n",
    "        return [[x * std_dev + mean for x in sublist] for sublist in data]\n",
    "    mean = sum(sum(sublist) for sublist in data) / (len(data) * len(data[0]))\n",
    "    std_dev = (sum((x - mean) ** 2 for sublist in data for x in sublist) / (len(data) * len(data[0]))) ** 0.5\n",
    "    standardized_data = [[(x - mean) / std_dev for x in sublist] for sublist in data]\n",
    "    return standardized_data, mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(labels, decoding=False, label_to_index=None):\n",
    "    \"\"\"\n",
    "    ラベルエンコーディングを行う関数\n",
    "\n",
    "    Args:\n",
    "        labels (list): カテゴリカルデータのリスト(デコードを行う際はエンコードした元文字列(現数値)のみを指定可能)\n",
    "        decoding (bool): デコードを行うかどうか(デコードを行う際は label_to_index を指定)\n",
    "        label_to_index (dict): ラベルとインデックスのマッピング\n",
    "    \n",
    "    Returns:\n",
    "        tuple: エンコードされたラベル、ラベルとインデックスのマッピング\n",
    "    \"\"\"\n",
    "    if decoding:\n",
    "        return [[list(label_to_index.keys())[list(label_to_index.values()).index(label)] for label in sublist] for sublist in labels]\n",
    "    str_labels = [label for label in sum(labels, []) if type(label) == str]\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(set(str_labels)))}\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] in label_to_index and type(labels[i][j]) == str:\n",
    "                labels[i][j] = label_to_index[labels[i][j]]\n",
    "    return labels, label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels, decoding=False, label_to_index=None):\n",
    "    \"\"\"\n",
    "    ワンホットエンコーディングを行う関数\n",
    "    \n",
    "    Args:\n",
    "        labels (list): カテゴリカルデータのリスト(デコードを行う際はエンコードした元文字列(現数値)のみを指定可能)\n",
    "        decoding (bool): デコードを行うかどうか(デコードを行う際は label_to_index を指定)\n",
    "        label_to_index (dict): ラベルとインデックスのマッピング\n",
    "    \n",
    "    Returns:\n",
    "        tuple: エンコードされたラベル、ラベルとインデックスのマッピング\n",
    "    \"\"\"\n",
    "    if decoding:\n",
    "        return[[k] for sublist in labels for i, x in enumerate(sublist) for k in label_to_index if x == 1 and i == label_to_index[k]]\n",
    "    str_labels = [label for label in sum(labels, []) if type(label) == str]\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(set(str_labels)))}\n",
    "    zeros = [0] * len(label_to_index)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] in label_to_index and type(labels[i][j]) == str:\n",
    "                labels[i][j] = zeros[:label_to_index[labels[i][j]]] + [1] + zeros[label_to_index[labels[i][j]]+1:]\n",
    "    return [[x for y in sublist for x in (y if isinstance(y, list) else [y])] for sublist in labels], label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, train_size=0.8, random_state=None):  # データセットを学習用とテスト用に分割\n",
    "    \"\"\"\n",
    "    データセットを学習用とテスト用に分割する関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        y (list): 正解ラベル\n",
    "        train_size (float): 学習データの割合\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 学習用データとテスト用データ\n",
    "    \"\"\"\n",
    "    if random_state is not None: random.seed(random_state)\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    X_train, y_train = [X[i] for i in indices[:int(n*train_size)]], [y[i] for i in indices[:int(n*train_size)]]\n",
    "    X_test, y_test = [X[i] for i in indices[int(n*train_size):]], [y[i] for i in indices[int(n*train_size):]]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000/10000, Loss: 0.0003608344, ████████████████████ 100%,     Training time: 2.68 seconds\n"
     ]
    }
   ],
   "source": [
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # 入力\n",
    "y = [[1], [0], [0], [1]]  # 出力\n",
    "X_train, y_train, X_test, y_test = split_dataset(X, y, train_size=0.8, random_state=42)  # データセットを学習用とテスト用に分割\n",
    "\n",
    "epochs = 10000  # エポック数\n",
    "learning_rate = 0.01  # 学習率\n",
    "layer_sizes = [len(X[0]), 8, 8, 8, len(y[0])]  # 各層のユニット数\n",
    "\n",
    "hidden_activation = \"relu\"\n",
    "output_activation = \"sigmoid\"\n",
    "loss = \"cross_entropy_loss\"\n",
    "\n",
    "random_seed = 42  # 乱数シード\n",
    "\n",
    "nn = Nn(hidden_activation, output_activation, loss, epochs, learning_rate, random_seed, layer_sizes)\n",
    "nn.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
