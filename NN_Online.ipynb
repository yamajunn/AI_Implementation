{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算用の関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネイピア数\n",
    "$$e = \\lim_{{x \\to \\infty}} \\left(1 + \\frac{1}{x}\\right)^x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def napiers_logarithm(x):\n",
    "    \"\"\"\n",
    "    ネイピア数を求める関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return (1 + 1 / x) ** x\n",
    "napier_number = napiers_logarithm(100000000)  # e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自然対数の近似値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln(x, max_iter=20, tol=1e-12):\n",
    "    \"\"\"\n",
    "    自然対数を求める関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "        max_iter (int): 最大反復回数\n",
    "        tol (float): 許容誤差\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    if x <= 0: raise ValueError(\"x must be positive\")\n",
    "    k = 0\n",
    "    while x > 2:\n",
    "        x /= 2\n",
    "        k += 1\n",
    "    while x < 0.5:\n",
    "        x *= 2\n",
    "        k -= 1\n",
    "    y = x - 1  # ln(1) = 0 付近の値から開始\n",
    "    for _ in range(max_iter):\n",
    "        prev_y = y\n",
    "        y -= (2.718281828459045**y - x) / (2.718281828459045**y)  # f(y) / f'(y)\n",
    "        if abs(y - prev_y) < tol:\n",
    "            break\n",
    "    return y + k * 0.6931471805599453  # ln(2) ≈ 0.693147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方根を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(x):\n",
    "    \"\"\"\n",
    "    平方根を求める関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    tolerance = 1e-10  # 許容誤差\n",
    "    estimate = x / 2.0  # 初期推定値\n",
    "    while True:\n",
    "        new_estimate = (estimate + x / estimate) / 2  # ニュートン法による更新\n",
    "        if abs(new_estimate - estimate) < tolerance:  # 収束したら終了\n",
    "            return new_estimate\n",
    "        estimate = new_estimate  # 推定値を更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 活性化関数およびその微分関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シグモイド関数\n",
    "$$Sigmoid(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "### シグモイド関数の微分\n",
    "$$Sigmoid'(x) = Sigmoid(x) \\cdot (1 - Sigmoid(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid 関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return 1 / (1 + napier_number ** -x)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Sigmoid 関数の微分\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU関数\n",
    "$$ReLU(x) = \\max(0, x)$$\n",
    "### ReLU関数の微分\n",
    "$$ReLU'(x) = \\begin{cases} \n",
    "1 & (x > 0) \\\\\n",
    "0 & (x ≤ 0)\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    \"\"\"\n",
    "    ReLU 関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return max(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    \"\"\"\n",
    "    ReLU 関数の微分\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return 1 if x > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU関数\n",
    "$$LeakyReLU(x) = \\begin{cases} \n",
    "x & (x > 0) \\\\ \n",
    "\\alpha x & (x ≤ 0)\n",
    "\\end{cases}$$\n",
    "\n",
    "### Leaky ReLU関数の微分\n",
    "$$LeakyReLU'(x) = \\begin{cases} \n",
    "1 & (x > 0) \\\\ \n",
    "\\alpha & (x ≤ 0)\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Leaky ReLU 関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "        alpha (float): ハイパーパラメータ\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return x if x > 0 else alpha * x\n",
    "\n",
    "def leaky_relu_derivative(x, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Leaky ReLU 関数の微分\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "        alpha (float): ハイパーパラメータ\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return 1 if x > 0 else alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恒等関数\n",
    "$$Identity(x) = x$$\n",
    "### 恒等関数の微分\n",
    "$$Identity'(x) = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    \"\"\"\n",
    "    恒等関数\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "def identity_derivative(x):\n",
    "    \"\"\"\n",
    "    恒等関数の微分\n",
    "\n",
    "    Args:\n",
    "        x (float): 入力\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fuctions = {\"sigmoid\": sigmoid, \"relu\": relu, \"leaky_relu\": leaky_relu, \"identity\": identity}\n",
    "derivative_fuctions = {\"sigmoid\": sigmoid_derivative, \"relu\": relu_derivative, \"leaky_relu\": leaky_relu_derivative, \"identity\": identity_derivative}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスエントロピー損失\n",
    "$$ L = -\\sum_{i=1}^{N} y_i \\cdot \\ln(\\hat{y}_i + \\epsilon)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    交差エントロピー損失関数\n",
    "\n",
    "    Args:\n",
    "        y_true (list): 正解ラベル\n",
    "        y_pred (list): 予測ラベル\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "    return -sum([t * ln(p + 1e-9) for t, p in zip(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均二乗誤差\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    平均二乗誤差を求める関数\n",
    "\n",
    "    Args:\n",
    "        y_true (list): 正解ラベル\n",
    "        y_pred (list): 予測ラベル\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "    return sum([(t - p) ** 2 for t, p in zip(y_true, y_pred)]) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均絶対誤差\n",
    "$$MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    平均絶対誤差を求める関数\n",
    "\n",
    "    Args:\n",
    "        y_true (list): 正解ラベル\n",
    "        y_pred (list): 予測ラベル\n",
    "    \n",
    "    Returns:\n",
    "        float: 出力\n",
    "    \"\"\"\n",
    "    if len(y_true) != len(y_pred): raise ValueError(\"Input lists must have the same length.\")\n",
    "    return sum([abs(t - p) for t, p in zip(y_true, y_pred)]) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークを初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layer_sizes):\n",
    "    \"\"\"\n",
    "    重みとバイアスを初期化する関数\n",
    "\n",
    "    Args:\n",
    "        layer_sizes (list): 各層のユニット数\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 重みとバイアス\n",
    "    \"\"\"\n",
    "    weights, biases = [], []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        limit = sqrt(6 / (layer_sizes[i] + layer_sizes[i+1]))  # 重みの初期化に使う乱数の範囲\n",
    "        weights.append([[random.uniform(-limit, limit) for _ in range(layer_sizes[i])] for _ in range(layer_sizes[i+1])])  # 重みは -limit から limit の間の乱数で初期化\n",
    "        biases.append([0 for _ in range(layer_sizes[i+1])])  # バイアスは0で初期化\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 順伝播処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(inputs, weights, biases, hidden_activation=\"relu\", output_activation=\"sigmoid\"):  # 順伝播処理\n",
    "    \"\"\"\n",
    "    順伝播処理を行う関数\n",
    "\n",
    "    Args:\n",
    "        inputs (list): 入力\n",
    "        weights (list): 重み\n",
    "        biases (list): バイアス\n",
    "    \n",
    "    Returns:\n",
    "        list: 出力\n",
    "    \"\"\"\n",
    "    activations = [inputs]\n",
    "    for W, b in zip(weights, biases):\n",
    "        z = [\n",
    "            sum([activations[-1][i] * W[j][i] for i in range(len(activations[-1]))]) + b[j]\n",
    "            for j in range(len(b))\n",
    "        ]\n",
    "        if W != weights[-1]:\n",
    "            activations.append([activation_fuctions[hidden_activation](z_i) for z_i in z])\n",
    "        else:\n",
    "            activations.append([activation_fuctions[output_activation](z_i) for z_i in z])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逆伝播処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(activations, y_true, weights, biases, learning_rate, hidden_activation=\"relu\", output_activation=\"sigmoid\"):  # 逆伝播処理\n",
    "    \"\"\"\n",
    "    逆伝播処理を行う関数\n",
    "\n",
    "    Args:\n",
    "        activations (list): 出力\n",
    "        y_true (list): 正解ラベル\n",
    "        weights (list): 重み\n",
    "        biases (list): バイアス\n",
    "        learning_rate (float): 学習率\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 重みとバイアス\n",
    "    \"\"\"\n",
    "    output_layer = activations[-1]\n",
    "    errors = [\n",
    "        (output_layer[i] - y_true[i]) * derivative_fuctions[output_activation](output_layer[i])\n",
    "        for i in range(len(y_true))\n",
    "    ]\n",
    "    deltas = [errors]\n",
    "    # 隠れ層の誤差を計算\n",
    "    for l in range(len(weights)-1, 0, -1):\n",
    "        hidden_errors = [\n",
    "            sum([deltas[0][k] * weights[l][k][j] for k in range(len(deltas[0]))]) * derivative_fuctions[hidden_activation](activations[l][j])\n",
    "            for j in range(len(activations[l]))\n",
    "        ]\n",
    "        deltas.insert(0, hidden_errors)\n",
    "    # 重みとバイアスを更新\n",
    "    for l in range(len(weights)):\n",
    "        for i in range(len(weights[l])):\n",
    "            for j in range(len(weights[l][i])):\n",
    "                weights[l][i][j] -= learning_rate * deltas[l][i] * activations[l][j]\n",
    "            biases[l][i] -= learning_rate * deltas[l][i]\n",
    "\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, layer_sizes, epochs, learning_rate, hidden_activation=\"relu\", output_activation=\"sigmoid\"):  # 学習\n",
    "    \"\"\"\n",
    "    ニューラルネットワークを学習する関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        y (list): 正解ラベル\n",
    "        layer_sizes (list): 各層のユニット数\n",
    "        epochs (int): エポック数\n",
    "        learning_rate (float): 学習率\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 重みとバイアス\n",
    "    \"\"\"\n",
    "    weights, biases = initialize_weights(layer_sizes)\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(len(X)):\n",
    "            activations = forward_propagation(X[i], weights, biases, hidden_activation, output_activation)\n",
    "            total_loss += cross_entropy_loss(y[i], activations[-1])\n",
    "            weights, biases = backward_propagation(activations, y[i], weights, biases, learning_rate, hidden_activation, output_activation)\n",
    "        m = epoch // (epochs // 20) + 1\n",
    "        print(f\"\\rEpoch {epoch+1}/{epochs}, Loss: {total_loss/len(X):.10f}, [{'+'*m}{' '*(20-m)}]{' '*5}\",end=\"\")\n",
    "    print(f\"Training time: {time.time()-start:.2f} seconds\")\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, biases, hidden_activation=\"relu\", output_activation=\"sigmoid\"):  # 予測\n",
    "    \"\"\"\n",
    "    予測を行う関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        weights (list): 重み\n",
    "        biases (list): バイアス\n",
    "    \n",
    "    Returns:\n",
    "        list: 出力\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for i in range(len(X)):  # Prediction\n",
    "        outputs.append(forward_propagation(X[i], weights, biases, hidden_activation, output_activation)[-1])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, y, predict):  # 予測精度の計算\n",
    "    \"\"\"\n",
    "    予測精度を計算する関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        y (list): 正解ラベル\n",
    "        predict (list): 予測値\n",
    "    \n",
    "    Returns:\n",
    "        float: 予測精度\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    total_loss = 0\n",
    "    for i in range(len(predict)):  # Prediction\n",
    "        print(f\"入力: {X[i]}, 正解: {y[i]}, 予測値: {[0 if p<0.5 else 1 for p in predict[i]]}, 出力地: {predict[i]}\")\n",
    "        accuracy += 1 if [0 if p<0.5 else 1 for p in predict[i]] == y[i] else 0\n",
    "        total_loss += cross_entropy_loss(y[i], predict[i])\n",
    "    print(f\"正解率: {accuracy / len(predict):.2f}, Loss: {total_loss / len(predict):.10f}\")\n",
    "    return accuracy / len(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, train_size=0.8):  # データセットを学習用とテスト用に分割\n",
    "    \"\"\"\n",
    "    データセットを学習用とテスト用に分割する関数\n",
    "\n",
    "    Args:\n",
    "        X (list): 入力\n",
    "        y (list): 正解ラベル\n",
    "        train_size (float): 学習データの割合\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 学習用データとテスト用データ\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    X_train, y_train = [X[i] for i in indices[:int(n*train_size)]], [y[i] for i in indices[:int(n*train_size)]]\n",
    "    X_test, y_test = [X[i] for i in indices[int(n*train_size):]], [y[i] for i in indices[int(n*train_size):]]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メインコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500, Loss: 0.0111651133, [++++++++++++++++++++]     Training time: 6.12 seconds\n",
      "入力: [0.2795043812685317, 0.4789926570128721], 正解: [0], 予測値: [0], 出力地: [3.354308413521764e-05]\n",
      "入力: [0.15936320396854087, 0.7778978129366259], 正解: [0], 予測値: [0], 出力地: [0.00459474442901708]\n",
      "入力: [0.3964239144722055, 0.050235567249439006], 正解: [0], 予測値: [0], 出力地: [3.7201398220393824e-06]\n",
      "入力: [0.00041513041642726733, 0.10568654678366685], 正解: [0], 予測値: [0], 出力地: [3.2532124080827366e-06]\n",
      "入力: [0.5199764329029976, 0.4296611660742279], 正解: [0], 予測値: [0], 出力地: [0.010746930977614253]\n",
      "入力: [0.20798535725159906, 0.6562070751464569], 正解: [0], 予測値: [0], 出力地: [0.00031858505868818357]\n",
      "入力: [0.27474793824914945, 0.9163087109616178], 正解: [1], 予測値: [1], 出力地: [0.9997474019057527]\n",
      "入力: [0.6045250699646221, 0.2001241925699958], 正解: [0], 予測値: [0], 出力地: [4.81772620585152e-05]\n",
      "入力: [0.8084413955921818, 0.19005925417885217], 正解: [0], 予測値: [0], 出力地: [0.1210756703716336]\n",
      "入力: [0.8201467806584752, 0.9087232989882436], 正解: [1], 予測値: [1], 出力地: [0.9999999999531606]\n",
      "正解率: 1.00, Loss: 0.0000252628\n"
     ]
    }
   ],
   "source": [
    "# データセット\n",
    "# X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # 入力\n",
    "# y = [[1, 1], [1, 0], [0, 1], [0, 0]]  # 出力\n",
    "\n",
    "X = [[random.random(), random.random()] for _ in range(100)]\n",
    "y = [[1] if x[0] + x[1] > 1 else [0] for x in X]\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(X, y, train_size=0.8)\n",
    "\n",
    "epochs = 500  # エポック数\n",
    "learning_rate = 0.01  # 学習率\n",
    "layer_sizes = [2, 8, 16, 8, 1]  # 各層のユニット数\n",
    "\n",
    "# X_train: 入力, y_train: 出力, layer_sizes: 各層のユニット数, epochs: エポック数, learning_rate: 学習率\n",
    "weights, biases = train(X_train, y_train, layer_sizes, epochs, learning_rate, hidden_activation=\"leaky_relu\", output_activation=\"sigmoid\")\n",
    "\n",
    "# X_test: テスト入力, weights: 重み, biases: バイアス\n",
    "predict_y = predict(X_test, weights, biases, hidden_activation=\"leaky_relu\", output_activation=\"sigmoid\")\n",
    "\n",
    "# X_test: テスト入力, y_test: テスト正解ラベル, predict_y: 予測値\n",
    "accuracy_num = accuracy(X_test, y_test, predict_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
